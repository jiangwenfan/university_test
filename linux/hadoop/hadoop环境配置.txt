0.前期准备工作:
0.1修改主机名
vim /etc/hostname
	hadoop1
0.2修改hosts文件
vim /etc/hosts
	192.168.100.1 hadoop1
0.3 给用户所有权限
vim /etc/sudoers
	root ALL=(ALL) ALL
	tony ALL=(ALL) ALL
0.4 关闭firewall,iptables,ufw
0.5 关闭selinux
0.6 创建目录
mkdir /opt/software #存储jar包等软件包
mkdir /opt/module #存储运行程序
chown tony:tony module/ software/

#上传jdk.tar.gz和hadoop.2.9.tar.gz包到/opt/software
#分别解压到/opt/module下
1.配置java环境变量:
vim /etc/profile
	export JAVA_HOME=/opt/module/jdk.1.8.8/
	export PATH=$PATH:$JAVA_HOME/bin
source /etc/profile #重载配置文件
java -version 

2.hadoop环境变量
tar -zxvf hadoop-2.9.tar.gz -C /opt/module
vim /etc/profile
	export HADOOP_HOME=/opt/module/hadoop-2.9.2
	export PATH=$PATH:$HADOOP_HOME/bin
	export PATH=$PATH:$HADOOP_HOME/sbin
source /etc/profile

1.配置hadoop-env.sh 
vim etc/hadoop/hadoop-env.sh 
	export 

2.配置core-size.xml


1.单机模式搭建:
案例1:
mkdir input/
cp etc/hadoop/*.xml input/
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar grep input/ output 'dfs[a-z.]+'
#最后一个通配字符.过滤掉/r/n 

案例2: wordcount
mkdir wcinput/
vim  wcinput/wc.input 
    apple banana pear monkey bear horse bear pear monkey horse bear bear 
hadoop jar share/hadoop/mapreduce/hadoop-mapreduce-examples-2.7.2.jar wordcount wcinput/ wcoutput
cat wcoutput/purt-r-00000  #查看结果
lssus:
1.为什么不能一直格式化namenode,格式化namenode需要注意什么？
cd hadoop/data/tmp/dfs
cat name/current/version #clusterID=...(集群ID)  name节点信息
cat data/current/version #clusterID=...(集群ID)  data节点信息
#多次格式化使得name和Data节点的集群ID信息不一样。

2.hdfs dfs -lsr / #查看多级目录 

